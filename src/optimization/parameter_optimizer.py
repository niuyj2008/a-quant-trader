"""
å‚æ•°ä¼˜åŒ–å¼•æ“ - Phase 9.2

æ”¯æŒGrid Searchå’ŒWalk-Forwardä¼˜åŒ–,ç¡®ä¿å‚æ•°æ³›åŒ–èƒ½åŠ›
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Tuple, Optional, Callable, Any
from loguru import logger
from itertools import product
from sklearn.model_selection import TimeSeriesSplit
import time


class ParameterOptimizer:
    """
    å‚æ•°ä¼˜åŒ–å™¨

    æ”¯æŒçš„ä¼˜åŒ–æ–¹æ³•:
    1. Grid Search: ç½‘æ ¼æœç´¢,éå†æ‰€æœ‰å‚æ•°ç»„åˆ
    2. Walk-Forward Optimization: æ»šåŠ¨çª—å£ä¼˜åŒ–,é¿å…è¿‡æ‹Ÿåˆ
    """

    def __init__(self, objective: str = 'sharpe_ratio'):
        """
        Args:
            objective: ä¼˜åŒ–ç›®æ ‡
                - 'sharpe_ratio': å¤æ™®æ¯”ç‡(é»˜è®¤)
                - 'calmar_ratio': Calmaræ¯”ç‡
                - 'total_return': æ€»æ”¶ç›Šç‡
                - 'win_rate': èƒœç‡
        """
        self.objective = objective
        self.optimization_history = []

    def grid_search(self,
                   strategy_class: Any,
                   param_grid: Dict[str, List],
                   data: pd.DataFrame,
                   backtest_func: Callable,
                   cv_folds: int = 5) -> Dict:
        """
        ç½‘æ ¼æœç´¢å‚æ•°ä¼˜åŒ–

        Args:
            strategy_class: ç­–ç•¥ç±»
            param_grid: å‚æ•°ç½‘æ ¼,å¦‚ {'momentum_period': [10,20,30], 'ma_short': [5,10]}
            data: å†å²æ•°æ®
            backtest_func: å›æµ‹å‡½æ•°,æ¥å—(strategy, data)è¿”å›metrics_dict
            cv_folds: K-Foldäº¤å‰éªŒè¯æŠ˜æ•°

        Returns:
            ä¼˜åŒ–ç»“æœå­—å…¸
        """
        logger.info(f"å¼€å§‹Grid Search: {len(param_grid)}ç»´å‚æ•°")

        # ç”Ÿæˆæ‰€æœ‰å‚æ•°ç»„åˆ
        param_names = list(param_grid.keys())
        param_values = list(param_grid.values())
        all_combinations = list(product(*param_values))

        total_combinations = len(all_combinations)
        logger.info(f"  æ€»ç»„åˆæ•°: {total_combinations}")

        results = []

        for idx, combo in enumerate(all_combinations, 1):
            params = dict(zip(param_names, combo))

            if idx % max(1, total_combinations // 10) == 0:
                logger.info(f"  è¿›åº¦: {idx}/{total_combinations} ({idx/total_combinations:.0%})")

            # K-Foldäº¤å‰éªŒè¯
            cv_scores = self._cross_validate(
                strategy_class, params, data, backtest_func, cv_folds
            )

            mean_score = np.mean(cv_scores)
            std_score = np.std(cv_scores)

            results.append({
                'params': params,
                'mean_score': mean_score,
                'std_score': std_score,
                'cv_scores': cv_scores,
                'stability': mean_score / std_score if std_score > 0 else 0,
            })

        # æŒ‰å¹³å‡å¾—åˆ†æ’åº
        results.sort(key=lambda x: x['mean_score'], reverse=True)

        # è®°å½•å†å²
        self.optimization_history.append({
            'method': 'grid_search',
            'param_grid': param_grid,
            'best_params': results[0]['params'],
            'best_score': results[0]['mean_score'],
            'n_combinations': total_combinations,
        })

        logger.info(f"Grid Searchå®Œæˆ: æœ€ä¼˜{self.objective}={results[0]['mean_score']:.4f}")

        return {
            'best_params': results[0]['params'],
            'best_score': results[0]['mean_score'],
            'all_results': results,
            'top_10': results[:10],
        }

    def _cross_validate(self,
                       strategy_class: Any,
                       params: Dict,
                       data: pd.DataFrame,
                       backtest_func: Callable,
                       cv_folds: int) -> List[float]:
        """K-Foldäº¤å‰éªŒè¯"""
        tscv = TimeSeriesSplit(n_splits=cv_folds)
        scores = []

        for train_idx, val_idx in tscv.split(data):
            train_data = data.iloc[train_idx]
            val_data = data.iloc[val_idx]

            # åˆ›å»ºç­–ç•¥å®ä¾‹
            strategy = strategy_class(**params)

            # å›æµ‹
            try:
                result = backtest_func(strategy, val_data)
                score = result.get(self.objective, 0)
                scores.append(score)
            except Exception as e:
                logger.warning(f"å›æµ‹å¤±è´¥: {params}, é”™è¯¯={e}")
                scores.append(-np.inf)

        return scores

    def walk_forward_optimization(self,
                                  strategy_class: Any,
                                  param_grid: Dict[str, List],
                                  data: pd.DataFrame,
                                  backtest_func: Callable,
                                  train_period: int = 252,
                                  test_period: int = 63) -> Dict:
        """
        Walk-Forwardä¼˜åŒ–(æœ€æ¥è¿‘å®ç›˜)

        æµç¨‹:
        1. åœ¨è®­ç»ƒæœŸä¼˜åŒ–å‚æ•°(Grid Search)
        2. åœ¨éªŒè¯æœŸä½¿ç”¨æœ€ä¼˜å‚æ•°å›æµ‹
        3. æ»šåŠ¨çª—å£é‡å¤

        Args:
            train_period: è®­ç»ƒæœŸå¤©æ•°(é»˜è®¤252å¤©=1å¹´)
            test_period: æµ‹è¯•æœŸå¤©æ•°(é»˜è®¤63å¤©=3ä¸ªæœˆ)

        Returns:
            ä¼˜åŒ–ç»“æœå­—å…¸
        """
        logger.info(f"å¼€å§‹Walk-Forwardä¼˜åŒ–: è®­ç»ƒ{train_period}å¤©, æµ‹è¯•{test_period}å¤©")

        dates = data.index
        results = []

        window_idx = 0
        for i in range(0, len(dates) - train_period - test_period, test_period):
            window_idx += 1

            train_start_idx = i
            train_end_idx = i + train_period
            test_start_idx = train_end_idx
            test_end_idx = test_start_idx + test_period

            train_data = data.iloc[train_start_idx:train_end_idx]
            test_data = data.iloc[test_start_idx:test_end_idx]

            logger.info(f"  çª—å£{window_idx}: è®­ç»ƒæœŸ{train_data.index[0]} ~ {train_data.index[-1]}")

            # åœ¨è®­ç»ƒæœŸä¼˜åŒ–å‚æ•°
            opt_result = self.grid_search(
                strategy_class, param_grid, train_data, backtest_func, cv_folds=3
            )

            best_params = opt_result['best_params']
            train_score = opt_result['best_score']

            # åœ¨æµ‹è¯•æœŸéªŒè¯
            strategy = strategy_class(**best_params)
            test_result = backtest_func(strategy, test_data)
            test_score = test_result.get(self.objective, 0)

            logger.info(f"    è®­ç»ƒæœŸ{self.objective}={train_score:.4f}, æµ‹è¯•æœŸ={test_score:.4f}")

            results.append({
                'window': window_idx,
                'train_period': f"{train_data.index[0]} ~ {train_data.index[-1]}",
                'test_period': f"{test_data.index[0]} ~ {test_data.index[-1]}",
                'best_params': best_params,
                'train_score': train_score,
                'test_score': test_score,
                'performance_ratio': test_score / train_score if train_score > 0 else 0,
            })

        # åˆ†æå‚æ•°ç¨³å®šæ€§
        param_stability = self._analyze_param_stability(results)

        # æ¨èå‚æ•°(å‡ºç°é¢‘ç‡æœ€é«˜çš„å‚æ•°ç»„åˆ)
        recommended_params = self._get_most_frequent_params(results)

        logger.info(f"Walk-Forwardä¼˜åŒ–å®Œæˆ: {len(results)}ä¸ªçª—å£")
        logger.info(f"  å¹³å‡æµ‹è¯•æœŸ{self.objective}={np.mean([r['test_score'] for r in results]):.4f}")
        logger.info(f"  æ¨èå‚æ•°: {recommended_params}")

        return {
            'results': results,
            'n_windows': len(results),
            'avg_train_score': np.mean([r['train_score'] for r in results]),
            'avg_test_score': np.mean([r['test_score'] for r in results]),
            'param_stability': param_stability,
            'recommended_params': recommended_params,
        }

    def _analyze_param_stability(self, results: List[Dict]) -> Dict:
        """åˆ†æå‚æ•°ç¨³å®šæ€§"""
        # ç»Ÿè®¡æ¯ä¸ªå‚æ•°çš„å€¼åˆ†å¸ƒ
        all_params = {}
        for r in results:
            for param_name, param_value in r['best_params'].items():
                if param_name not in all_params:
                    all_params[param_name] = []
                all_params[param_name].append(param_value)

        # è®¡ç®—æ¯ä¸ªå‚æ•°çš„æ ‡å‡†å·®(å½’ä¸€åŒ–)
        stability = {}
        for param_name, values in all_params.items():
            unique_values = len(set(values))
            total_values = len(values)

            # ç¨³å®šæ€§ = 1 - (å”¯ä¸€å€¼æ•° / æ€»æ•°)
            # å¦‚æœæ‰€æœ‰çª—å£éƒ½ç”¨åŒä¸€ä¸ªå€¼,ç¨³å®šæ€§=1.0
            # å¦‚æœæ¯ä¸ªçª—å£éƒ½ä¸åŒ,ç¨³å®šæ€§=0.0
            stability_score = 1.0 - (unique_values - 1) / total_values

            stability[param_name] = {
                'score': stability_score,
                'unique_values': unique_values,
                'total_values': total_values,
                'value_distribution': dict(pd.Series(values).value_counts()),
            }

        return stability

    def _get_most_frequent_params(self, results: List[Dict]) -> Dict:
        """è·å–å‡ºç°é¢‘ç‡æœ€é«˜çš„å‚æ•°ç»„åˆ"""
        # ç»Ÿè®¡æ¯ä¸ªå‚æ•°å€¼çš„å‡ºç°æ¬¡æ•°
        param_counts = {}

        for r in results:
            for param_name, param_value in r['best_params'].items():
                if param_name not in param_counts:
                    param_counts[param_name] = {}

                if param_value not in param_counts[param_name]:
                    param_counts[param_name][param_value] = 0

                param_counts[param_name][param_value] += 1

        # é€‰æ‹©æ¯ä¸ªå‚æ•°å‡ºç°æœ€é¢‘ç¹çš„å€¼
        most_frequent = {}
        for param_name, value_counts in param_counts.items():
            most_frequent[param_name] = max(value_counts, key=value_counts.get)

        return most_frequent

    def random_search(self,
                     strategy_class: Any,
                     param_distributions: Dict[str, Tuple],
                     data: pd.DataFrame,
                     backtest_func: Callable,
                     n_iter: int = 50,
                     cv_folds: int = 5) -> Dict:
        """
        éšæœºæœç´¢å‚æ•°ä¼˜åŒ–(é€‚åˆé«˜ç»´å‚æ•°ç©ºé—´)

        Args:
            param_distributions: å‚æ•°åˆ†å¸ƒ,å¦‚ {'momentum_period': (10, 60), 'ma_short': (5, 20)}
            n_iter: éšæœºé‡‡æ ·æ¬¡æ•°

        Returns:
            ä¼˜åŒ–ç»“æœå­—å…¸
        """
        logger.info(f"å¼€å§‹Random Search: {n_iter}æ¬¡éšæœºé‡‡æ ·")

        results = []

        for idx in range(n_iter):
            # éšæœºé‡‡æ ·å‚æ•°
            params = {}
            for param_name, (min_val, max_val) in param_distributions.items():
                if isinstance(min_val, int) and isinstance(max_val, int):
                    params[param_name] = np.random.randint(min_val, max_val + 1)
                else:
                    params[param_name] = np.random.uniform(min_val, max_val)

            if (idx + 1) % max(1, n_iter // 10) == 0:
                logger.info(f"  è¿›åº¦: {idx+1}/{n_iter} ({(idx+1)/n_iter:.0%})")

            # K-Foldäº¤å‰éªŒè¯
            cv_scores = self._cross_validate(
                strategy_class, params, data, backtest_func, cv_folds
            )

            mean_score = np.mean(cv_scores)
            std_score = np.std(cv_scores)

            results.append({
                'params': params,
                'mean_score': mean_score,
                'std_score': std_score,
                'cv_scores': cv_scores,
            })

        # æ’åº
        results.sort(key=lambda x: x['mean_score'], reverse=True)

        logger.info(f"Random Searchå®Œæˆ: æœ€ä¼˜{self.objective}={results[0]['mean_score']:.4f}")

        return {
            'best_params': results[0]['params'],
            'best_score': results[0]['mean_score'],
            'all_results': results,
            'top_10': results[:10],
        }

    def generate_optimization_report(self, optimization_result: Dict,
                                    method: str = 'grid_search') -> str:
        """
        ç”Ÿæˆå‚æ•°ä¼˜åŒ–æŠ¥å‘Š

        Args:
            optimization_result: ä¼˜åŒ–ç»“æœ
            method: ä¼˜åŒ–æ–¹æ³•('grid_search', 'walk_forward', 'random_search')

        Returns:
            æŠ¥å‘Šå­—ç¬¦ä¸²
        """
        report = []
        report.append("=" * 70)
        report.append(f"å‚æ•°ä¼˜åŒ–æŠ¥å‘Š - {method.upper()}")
        report.append("=" * 70)

        if method == 'walk_forward':
            report.append(f"\nğŸ“Š Walk-Forwardä¼˜åŒ–ç»“æœ:")
            report.append(f"  çª—å£æ•°: {optimization_result['n_windows']}")
            report.append(f"  å¹³å‡è®­ç»ƒæœŸ{self.objective}: {optimization_result['avg_train_score']:.4f}")
            report.append(f"  å¹³å‡æµ‹è¯•æœŸ{self.objective}: {optimization_result['avg_test_score']:.4f}")
            report.append(f"  æ³›åŒ–èƒ½åŠ›: {optimization_result['avg_test_score']/optimization_result['avg_train_score']:.2%}")

            report.append(f"\n\nğŸ¯ æ¨èå‚æ•°:")
            for param_name, param_value in optimization_result['recommended_params'].items():
                report.append(f"  {param_name}: {param_value}")

            report.append(f"\n\nğŸ“ˆ å‚æ•°ç¨³å®šæ€§:")
            for param_name, stability_info in optimization_result['param_stability'].items():
                report.append(f"  {param_name}:")
                report.append(f"    ç¨³å®šæ€§å¾—åˆ†: {stability_info['score']:.2f}")
                report.append(f"    å”¯ä¸€å€¼æ•°: {stability_info['unique_values']}/{stability_info['total_values']}")
                report.append(f"    å€¼åˆ†å¸ƒ: {stability_info['value_distribution']}")

        else:  # grid_search or random_search
            report.append(f"\nğŸ† æœ€ä¼˜å‚æ•°:")
            for param_name, param_value in optimization_result['best_params'].items():
                report.append(f"  {param_name}: {param_value}")

            report.append(f"\n  {self.objective}: {optimization_result['best_score']:.4f}")

            if 'top_10' in optimization_result:
                report.append(f"\n\nğŸ“Š Top 10å‚æ•°ç»„åˆ:")
                for i, result in enumerate(optimization_result['top_10'][:10], 1):
                    report.append(f"\n  {i}. {self.objective}={result['mean_score']:.4f}")
                    report.append(f"     å‚æ•°: {result['params']}")

        report.append("\n" + "=" * 70)

        return "\n".join(report)


def quick_optimize(strategy_class: Any,
                  param_grid: Dict[str, List],
                  data: pd.DataFrame,
                  backtest_func: Callable,
                  method: str = 'grid_search',
                  objective: str = 'sharpe_ratio') -> Dict:
    """
    å¿«é€Ÿå‚æ•°ä¼˜åŒ–(ä¾¿æ·å‡½æ•°)

    Args:
        method: ä¼˜åŒ–æ–¹æ³•('grid_search', 'walk_forward', 'random_search')

    Returns:
        ä¼˜åŒ–ç»“æœ
    """
    optimizer = ParameterOptimizer(objective=objective)

    if method == 'walk_forward':
        result = optimizer.walk_forward_optimization(
            strategy_class, param_grid, data, backtest_func
        )
    elif method == 'random_search':
        # å°†param_gridè½¬ä¸ºparam_distributions
        param_distributions = {
            name: (min(values), max(values))
            for name, values in param_grid.items()
        }
        result = optimizer.random_search(
            strategy_class, param_distributions, data, backtest_func, n_iter=50
        )
    else:  # grid_search
        result = optimizer.grid_search(
            strategy_class, param_grid, data, backtest_func, cv_folds=5
        )

    # ç”ŸæˆæŠ¥å‘Š
    report = optimizer.generate_optimization_report(result, method)

    return {
        **result,
        'report': report,
    }
